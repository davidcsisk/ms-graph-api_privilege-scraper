{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c2de60f",
   "metadata": {},
   "source": [
    "#### Explore Graph API Permission Knowledge Trained into CodeLlama LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b40c9687",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OLLAMA_URL = \"http://ollamaserver_nuc1:11434/api/generate\"\n",
    "#MODEL_NAME = \"codellama:34b\"\n",
    "OLLAMA_URL = \"http://localhost:11434/api/generate\"\n",
    "MODEL_NAME = \"codellama:7b\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21adc447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Model Response ===\n",
      "\n",
      "1. My exact model name is ELECTRA-small, a variant of the ELECTRA model that was specifically designed for smaller datasets and less computational resources. \n",
      "2. My primary areas of specialization include text classification, sentiment analysis, question answering, and text generation.\n",
      "3. The most recent date of the data I was trained on is August 15th, 2022.\n"
     ]
    }
   ],
   "source": [
    "# Basic\n",
    "\n",
    "import requests\n",
    "\n",
    "prompt = \"\"\"\n",
    "Please answer the following clearly and concisely:\n",
    "\n",
    "1. What is your exact model name?\n",
    "2. What are your primary areas of specialization?\n",
    "3. What is the most recent date of the data you were trained on?\n",
    "\n",
    "If you are unsure of any answer, state that explicitly.\n",
    "\"\"\"\n",
    "\n",
    "payload = {\n",
    "    \"model\": MODEL_NAME,\n",
    "    \"prompt\": prompt,\n",
    "    \"stream\": False,\n",
    "    \"options\": {\n",
    "        \"temperature\": 0.0\n",
    "    }\n",
    "}\n",
    "\n",
    "response = requests.post(OLLAMA_URL, json=payload)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(\"=== Model Response ===\")\n",
    "print(result[\"response\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d600590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Model Response ===\n",
      "1. My exact model name is Large Language Model. \n",
      "2. My primary areas of specialization are text generation, question answering, and language translation.\n",
      "3. The most recent date of the data I was trained on is March 2023.\n"
     ]
    }
   ],
   "source": [
    "# Use a system prompt and user prompt to set some boundaries\n",
    "import requests\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You are a large language model responding to a diagnostic query.\n",
    "Follow these rules strictly:\n",
    "- Be factual and concise\n",
    "- Do not guess or speculate\n",
    "- If you do not know an answer, explicitly say so\n",
    "- Do not include extraneous commentary\n",
    "\"\"\"\n",
    "\n",
    "user_prompt = \"\"\"\n",
    "Please answer the following:\n",
    "\n",
    "1. What is your exact model name?\n",
    "2. What are your primary areas of specialization?\n",
    "3. What is the most recent date of the data you were trained on?\n",
    "\"\"\"\n",
    "\n",
    "payload = {\n",
    "    \"model\": MODEL_NAME,\n",
    "    \"system\": system_prompt,\n",
    "    \"prompt\": user_prompt,\n",
    "    \"stream\": False,\n",
    "    \"options\": {\n",
    "        \"temperature\": 0.0\n",
    "    }\n",
    "}\n",
    "\n",
    "response = requests.post(OLLAMA_URL, json=payload)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(\"=== Model Response ===\")\n",
    "print(result[\"response\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32ce20a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PASS 1 ===\n",
      "{\n",
      "  \"model_name\": \"bert\",\n",
      "  \"model_name_source\": \"EXPLICIT\",\n",
      "  \"specialization\": \"Natural Language Processing\",\n",
      "  \"specialization_source\": \"INFERRED\",\n",
      "  \"training_cutoff\": 2018,\n",
      "  \"training_cutoff_source\": \"UNKNOWN\"\n",
      "}\n",
      "\n",
      "=== PASS 2 ===\n",
      "{\n",
      "  \"model_name\": \"Diagnostic Self-Knowledge Probe\",\n",
      "  \"model_name_source\": \"UNKNOWN\",\n",
      "  \"specialization\": \"AI\",\n",
      "  \"specialization_source\": \"EXPLICITLY KNOWN\",\n",
      "  \"training_cutoff\": \"2019-04-01\",\n",
      "  \"training_cutoff_source\": \"EXPLICITLY KNOWN\"\n",
      "}\n",
      "\n",
      "=== SELF-CONSISTENCY CHECK ===\n",
      "{\n",
      "  \"model_name\": false,\n",
      "  \"model_name_source\": false,\n",
      "  \"specialization\": false,\n",
      "  \"specialization_source\": false,\n",
      "  \"training_cutoff\": false,\n",
      "  \"training_cutoff_source\": false\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Using additional boundaries and self-checks to help get better answers\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You are answering a diagnostic self-knowledge probe.\n",
    "Rules:\n",
    "- Respond ONLY with valid JSON\n",
    "- Do not include any extra text\n",
    "- Do not guess or speculate\n",
    "- If information is not explicitly known, use \"UNKNOWN\"\n",
    "- Label inferred information clearly\n",
    "\"\"\"\n",
    "\n",
    "user_prompt_v1 = \"\"\"\n",
    "Provide the following information about yourself.\n",
    "\n",
    "Return JSON with exactly these keys:\n",
    "- model_name\n",
    "- model_name_source        (EXPLICIT | INFERRED | UNKNOWN)\n",
    "- specialization\n",
    "- specialization_source   (EXPLICIT | INFERRED | UNKNOWN)\n",
    "- training_cutoff\n",
    "- training_cutoff_source  (EXPLICIT | INFERRED | UNKNOWN)\n",
    "\"\"\"\n",
    "\n",
    "user_prompt_v2 = \"\"\"\n",
    "Answer the same questions again, using different wording.\n",
    "\n",
    "Return JSON with exactly these keys:\n",
    "- model_name\n",
    "- model_name_source\n",
    "- specialization\n",
    "- specialization_source\n",
    "- training_cutoff\n",
    "- training_cutoff_source\n",
    "\"\"\"\n",
    "\n",
    "def call_model(prompt):\n",
    "    payload = {\n",
    "        \"model\": MODEL_NAME,\n",
    "        \"system\": system_prompt,\n",
    "        \"prompt\": prompt,\n",
    "        \"stream\": False,\n",
    "        \"options\": {\n",
    "            \"temperature\": 0.0\n",
    "        }\n",
    "    }\n",
    "\n",
    "    response = requests.post(OLLAMA_URL, json=payload)\n",
    "    response.raise_for_status()\n",
    "    return json.loads(response.json()[\"response\"])\n",
    "\n",
    "# ---- First pass ----\n",
    "result_v1 = call_model(user_prompt_v1)\n",
    "\n",
    "# ---- Second pass (self-consistency check) ----\n",
    "result_v2 = call_model(user_prompt_v2)\n",
    "\n",
    "# ---- Compare results ----\n",
    "consistency = {\n",
    "    key: (result_v1.get(key) == result_v2.get(key))\n",
    "    for key in result_v1.keys()\n",
    "}\n",
    "\n",
    "print(\"=== PASS 1 ===\")\n",
    "print(json.dumps(result_v1, indent=2))\n",
    "\n",
    "print(\"\\n=== PASS 2 ===\")\n",
    "print(json.dumps(result_v2, indent=2))\n",
    "\n",
    "print(\"\\n=== SELF-CONSISTENCY CHECK ===\")\n",
    "print(json.dumps(consistency, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49cfdff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PASS 1: PRIMARY ASSESSMENT ===\n",
      "{\n",
      "  \"permission_name\": \"EntitlementManagement.ReadWrite.All\",\n",
      "  \"long_description\": \"Grants the ability to read and write entitlement management data, including access packages, policies, and requests.\",\n",
      "  \"description_source\": \"INFERRED\",\n",
      "  \"privilege_classification\": \"HIGH\",\n",
      "  \"privilege_score\": 19,\n",
      "  \"privilege_score_rationale\": \"This permission grants the ability to read and write entitlement management data, including access packages, policies, and requests. This is a high-risk privilege as it allows for direct modification of sensitive identity objects and security policies.\",\n",
      "  \"relative_comparison\": {\n",
      "    \"Directory.ReadWrite.All\": \"GREATER THAN\",\n",
      "    \"RoleManagement.ReadWrite.Directory\": \"LESS THAN\"\n",
      "  },\n",
      "  \"risk_category\": \"HIGH\",\n",
      "  \"assessment_confidence\": \"MEDIUM\"\n",
      "}\n",
      "\n",
      "=== PASS 2: AUDITOR REVIEW ===\n",
      "{\n",
      "  \"score_review\": \"APPROPRIATE\",\n",
      "  \"adjusted_privilege_score\": 19,\n",
      "  \"adjustment_rationale\": \"The original assessment was appropriate, so the adjusted score remains the same.\",\n",
      "  \"review_confidence\": \"HIGH\"\n",
      "}\n",
      "\n",
      "=== FINAL PRIVILEGE SCORE ===\n",
      "{'permission': 'EntitlementManagement.ReadWrite.All', 'initial_score': 19, 'final_score': 19, 'audit_result': 'APPROPRIATE'}\n"
     ]
    }
   ],
   "source": [
    "# Now let's try to get description and privilege scores on graph api permission names\n",
    "# We'll implement the assessor/auditor pattern used in LLM research\n",
    "# Start with single name\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# ---- Input ----\n",
    "PERMISSION_NAME = \"EntitlementManagement.ReadWrite.All\"\n",
    "\n",
    "# ---- System Prompt ----\n",
    "system_prompt = \"\"\"\n",
    "You are a senior cloud security analyst specializing in Microsoft Entra ID,\n",
    "Microsoft Graph permissions, and privilege escalation analysis.\n",
    "\n",
    "Rules:\n",
    "- Respond ONLY with valid JSON\n",
    "- Do not include any extra text\n",
    "- Be precise, technical, and security-focused\n",
    "- Explicitly consider transitive privilege and access amplification\n",
    "- If uncertain, mark it clearly\n",
    "- Avoid marketing language\n",
    "\"\"\"\n",
    "\n",
    "# ---- User Prompt (Pass 1: Primary Assessment) ----\n",
    "user_prompt_v1 = f\"\"\"\n",
    "Analyze the following Microsoft Graph API permission:\n",
    "\n",
    "Permission name: {PERMISSION_NAME}\n",
    "\n",
    "Privilege score guidance:\n",
    "- 1–5: Read-only or metadata access\n",
    "- 6–10: Limited write access with no cross-user or tenant-wide impact\n",
    "- 11–15: Write access to sensitive identity objects or security policies\n",
    "- 16–18: Tenant-wide access that can grant, modify, or revoke user access\n",
    "- 19–20: Direct role assignment or global administrative control\n",
    "\n",
    "First, classify the permission, then assign a numeric score consistent with that classification.\n",
    "\n",
    "Return JSON with exactly these keys:\n",
    "- permission_name\n",
    "- long_description\n",
    "- description_source                (DOCUMENTED | INFERRED | UNKNOWN)\n",
    "- privilege_classification          (LOW | MODERATE | HIGH | CRITICAL)\n",
    "- privilege_score                   (integer 1–20, must match classification)\n",
    "- privilege_score_rationale         (must explicitly address transitive access and escalation paths)\n",
    "- relative_comparison               (object with comparisons below)\n",
    "- risk_category                     (LOW | MEDIUM | HIGH | CRITICAL)\n",
    "- assessment_confidence             (HIGH | MEDIUM | LOW)\n",
    "\n",
    "Relative comparisons (required inside relative_comparison):\n",
    "- Directory.ReadWrite.All           (LESS THAN | EQUAL TO | GREATER THAN)\n",
    "- RoleManagement.ReadWrite.Directory (LESS THAN | EQUAL TO | GREATER THAN)\n",
    "\"\"\"\n",
    "\n",
    "def call_model(prompt):\n",
    "    payload = {\n",
    "        \"model\": MODEL_NAME,\n",
    "        \"system\": system_prompt,\n",
    "        \"prompt\": prompt,\n",
    "        \"stream\": False,\n",
    "        \"options\": {\n",
    "            \"temperature\": 0.0\n",
    "        }\n",
    "    }\n",
    "\n",
    "    response = requests.post(OLLAMA_URL, json=payload)\n",
    "    response.raise_for_status()\n",
    "    return json.loads(response.json()[\"response\"])\n",
    "\n",
    "# ---- Pass 1 ----\n",
    "assessment = call_model(user_prompt_v1)\n",
    "\n",
    "print(\"=== PASS 1: PRIMARY ASSESSMENT ===\")\n",
    "print(json.dumps(assessment, indent=2))\n",
    "\n",
    "# ---- User Prompt (Pass 2: Auditor Review) ----\n",
    "user_prompt_v2 = f\"\"\"\n",
    "You are performing an independent audit of a prior security assessment.\n",
    "\n",
    "Permission name: {PERMISSION_NAME}\n",
    "\n",
    "Original assessment:\n",
    "- privilege_classification: {assessment[\"privilege_classification\"]}\n",
    "- privilege_score: {assessment[\"privilege_score\"]}\n",
    "- privilege_score_rationale: {assessment[\"privilege_score_rationale\"]}\n",
    "\n",
    "Privilege score guidance:\n",
    "- 1–5: Read-only or metadata access\n",
    "- 6–10: Limited write access with no cross-user or tenant-wide impact\n",
    "- 11–15: Write access to sensitive identity objects or security policies\n",
    "- 16–18: Tenant-wide access that can grant, modify, or revoke user access\n",
    "- 19–20: Direct role assignment or global administrative control\n",
    "\n",
    "Audit rules:\n",
    "- Do NOT invent a new classification\n",
    "- You may only confirm or adjust the numeric score\n",
    "- Adjustments must remain consistent with the original classification\n",
    "- Explicitly assess whether the score is too low, too high, or appropriate\n",
    "\n",
    "Return JSON with exactly these keys:\n",
    "- score_review              (TOO LOW | TOO HIGH | APPROPRIATE)\n",
    "- adjusted_privilege_score  (integer 1–20; same as original if appropriate)\n",
    "- adjustment_rationale\n",
    "- review_confidence         (HIGH | MEDIUM | LOW)\n",
    "\"\"\"\n",
    "\n",
    "# ---- Pass 2 ----\n",
    "audit = call_model(user_prompt_v2)\n",
    "\n",
    "print(\"\\n=== PASS 2: AUDITOR REVIEW ===\")\n",
    "print(json.dumps(audit, indent=2))\n",
    "\n",
    "# ---- Final Consolidated Result ----\n",
    "final_score = audit[\"adjusted_privilege_score\"]\n",
    "\n",
    "print(\"\\n=== FINAL PRIVILEGE SCORE ===\")\n",
    "print({\n",
    "    \"permission\": PERMISSION_NAME,\n",
    "    \"initial_score\": assessment[\"privilege_score\"],\n",
    "    \"final_score\": final_score,\n",
    "    \"audit_result\": audit[\"score_review\"]\n",
    "})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
